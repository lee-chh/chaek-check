import os
import time
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# 2. ì„ë² ë”© ëª¨ë¸ ì„¤ì •
embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

# 3. ê²½ë¡œ ì„¤ì •
DATA_FOLDER = "./data"
DB_PATH = "./db_chroma"

def ingest_data():
    if not os.path.exists(DATA_FOLDER):
        print(f"âŒ '{DATA_FOLDER}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return

    # PDF íŒŒì¼ ì°¾ê¸°
    pdf_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith('.pdf')]
    if not pdf_files:
        print(f"âŒ '{DATA_FOLDER}' í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return

    documents = []
    print(f"ğŸ“‚ ë°œê²¬ëœ ê·œì •ì§‘: {pdf_files}")

    # 4. PDF ë¡œë“œ
    for pdf_file in pdf_files:
        file_path = os.path.join(DATA_FOLDER, pdf_file)
        print(f"ğŸš€ ë¡œë”© ì¤‘: {pdf_file} ...")
        loader = PyPDFLoader(file_path)
        docs = loader.load()
        documents.extend(docs)

    print(f"âœ… ì´ {len(documents)} í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ!")

    # 5. í…ìŠ¤íŠ¸ ìª¼ê°œê¸°
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=5000,
        chunk_overlap=50,
        separators=["\n\n", "\n", " ", ""]
    )
    splits = text_splitter.split_documents(documents)
    print(f"âœ‚ï¸ ì´ {len(splits)}ê°œì˜ ì¡°ê°(Chunk)ìœ¼ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # 6. ë²¡í„° DB ìƒì„± (ì—¬ê¸°ì„œë¶€í„° ìˆ˜ì •ë¨!)
    print("ğŸ’¾ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹œì‘...")

    # ë¹ˆ DBë¥¼ ë¨¼ì € ë§Œë“­ë‹ˆë‹¤
    vectorstore = Chroma(
        persist_directory=DB_PATH,
        embedding_function=embeddings
    )

    # ğŸ’¡ ì¤‘ìš”: 100ê°œì”© ëŠì–´ì„œ ì €ì¥ (Batch Processing)
    batch_size = 100
    total_batches = (len(splits) + batch_size - 1) // batch_size

    for i in range(0, len(splits), batch_size):
        batch = splits[i : i + batch_size]
        print(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘... ({i // batch_size + 1}/{total_batches}) - {len(batch)}ê°œ ì €ì¥")
        vectorstore.add_documents(batch)
        time.sleep(0.5) # API ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ 0.5ì´ˆ íœ´ì‹

    print("ğŸ‰ ëª¨ë“  ë°ì´í„° ì €ì¥ ì™„ë£Œ! './db_chroma' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    ingest_data()
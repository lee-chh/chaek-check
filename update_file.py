import os
import argparse
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()

DATA_FOLDER = "./data"
DB_PATH = "./db_chroma"

def update_specific_file(filename):
    # 2. DB ì—°ê²°
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)

    # ì‚­ì œí•  ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ (ë©”íƒ€ë°ì´í„°ì˜ 'source'ì™€ ì¼ì¹˜í•´ì•¼ í•¨)
    # ingest.pyì—ì„œ "./data/íŒŒì¼ëª…" í˜•íƒœë¡œ ì €ì¥í–ˆì„ ê²ƒì…ë‹ˆë‹¤.
    target_source = f"./data/{filename}"

    print(f"ğŸ” '{filename}' íŒŒì¼ êµì²´ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    # 3. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (Delete)
    # ChromaDBì—ì„œ source ë©”íƒ€ë°ì´í„°ê°€ ì¼ì¹˜í•˜ëŠ” ëª¨ë“  ì²­í¬ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
    try:
        # í˜„ì¬ DBì— í•´ë‹¹ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸ (getìœ¼ë¡œ ì¡°íšŒ)
        existing_docs = vectorstore.get(where={"source": target_source})
        if len(existing_docs['ids']) == 0:
            print(f"âš ï¸ ê²½ê³ : DBì—ì„œ '{target_source}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì‚­ì œ ê±´ë„ˆëœ€/ìƒˆë¡œ ì¶”ê°€ë§Œ ì§„í–‰)")
        else:
            vectorstore.delete(where={"source": target_source})
            print(f"ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ! ({len(existing_docs['ids'])}ê°œì˜ ì²­í¬ ì‚­ì œë¨)")
    except Exception as e:
        print(f"âŒ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    # 4. ìˆ˜ì •ëœ íŒŒì¼ ë¡œë“œ ë° ì¶”ê°€ (Add)
    file_path = os.path.join(DATA_FOLDER, filename)
    if not os.path.exists(file_path):
        print(f"âŒ ì˜¤ë¥˜: '{file_path}' íŒŒì¼ì´ ì‹¤ì œ í´ë”ì— ì—†ìŠµë‹ˆë‹¤!")
        return

    print(f"ğŸš€ ìˆ˜ì •ëœ íŒŒì¼ ë¡œë”© ì¤‘: {filename} ...")
    loader = PyPDFLoader(file_path)
    docs = loader.load()

    # 5. í…ìŠ¤íŠ¸ ë¶„í•  (ingest.pyì™€ ë™ì¼í•œ ì„¤ì • ìœ ì§€ í•„ìˆ˜!)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,     # ingest.pyì™€ ë§ì¶¤
        chunk_overlap=50,   # ingest.pyì™€ ë§ì¶¤
        separators=["\n\n", "\n", " ", ""]
    )
    splits = text_splitter.split_documents(docs)
    print(f"âœ‚ï¸ {len(splits)}ê°œì˜ ìƒˆë¡œìš´ ì¡°ê°ìœ¼ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # 6. DBì— ì¶”ê°€
    print("ğŸ’¾ ìƒˆë¡œìš´ ë°ì´í„° ì €ì¥ ì¤‘...")
    vectorstore.add_documents(splits)
    print(f"ğŸ‰ '{filename}' êµì²´ ì™„ë£Œ!")

if __name__ == "__main__":
    # ì‚¬ìš©ë²•: python update_file.py íŒŒì¼ëª….pdf
    import sys
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python update_file.py [íŒŒì¼ëª…]")
        print("ì˜ˆì‹œ: python update_file.py football_kleague_regulation_2025.pdf")
    else:
        target_file = sys.argv[1]
        update_specific_file(target_file)